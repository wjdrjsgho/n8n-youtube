# ![Thumbail](https://i.ytimg.com/vi_webp/0h6gfMqpx_0/sddefault.webp)
## **팟캐스트 소개 및 게스트 박진형 엔지니어**

- 호스트 '평범한 직장인'이 팟캐스트 'Ordinary People'을 소개함.

- AI가 사람들의 삶을 변화시키는 특별한 방법을 탐구하는 방송임.

- 오늘의 주제는 '클라우드 코드 사용 중단'이며, 게스트는 클라우드 코드 사용량 1위를 달성한 Psionic AI의 박진형 엔지니어임.

- 박진형 엔지니어는 Psionic AI의 Ultrathink Engineering에서 머신러닝 및 백엔드 엔지니어링을 담당함.

- 주로 AI 에이전트의 개발부터 서빙(serving)까지, 실제 기업 고객과의 연결을 구축하는 작업을 수행함.

## **Psionic AI 소개 및 기업 고객의 AI 니즈**

- Psionic AI는 기업의 생성형 AI 도입 어려움 해소에 주력함.

- 다양한 ML 및 DevOps 팀 필요성 때문에 기업이 AI 도입에 어려움을 겪음.

- Psionic AI는 이러한 기업들이 AI를 쉽게 도입하고 활용할 수 있도록 중간 플랫폼을 지속적으로 제공함.

- 기업 고객의 가장 흔한 AI 활용 니즈는 AI 에이전트 활용임.

- 기업은 AI 도입 시 긍정적 측면(Upside)과 부정적 측면(Downside)을 모두 고려해야 함.

- <strong>긍정적 측면 (Upside):</strong>

- 20~30년 축적된 사내 문서 기반으로 AI가 학습하여, 원하는 시점에 실수 없이 적절한 답변 제공을 원함.

- 'Agentic' 방식으로 활용: 다양한 유스케이스를 코드나 함수로 잘 정리하고, 흐름에 따라 정의하고 실행하기를 원함 (예: Agentic AI, Agent Retrieval).

- <strong>부정적 측면 (Downside):</strong>

- AI가 나쁜 답변이나 잘못된 답변을 주거나, 원치 않는 행동으로 문제를 일으킬까 우려함.

- 개인 정보가 답변에 노출되는 등 사소해 보이지만 치명적인 문제가 발생할 수 있음을 걱정함.

- 기업은 긍정적/부정적 측면 모두를 고려해야 하는 지점에서 가장 많은 고민을 함.

## **RAG에서 Agent AI로의 전환과 그 의미**

- 지난해 기업들은 RAG(Retrieval Augmented Generation) 구축에 총력을 기울였고, 올해는 에이전트 AI 도입 시도가 많음.

- 생성형 AI 도입에 대한 시장의 가장 큰 기대는 사람/인력을 컴퓨터나 AI로 대체하는 것임.

- AI는 다양한 유스케이스와 액션을 수행할 수 있어야 이러한 기대를 충족할 수 있음.

- 단일하고 특정 작업에만 국한되면 기대치 충족이 어려움.

- <strong>RAG의 한계 예시:</strong>

- "회사 연간 매출 알려줘" 같은 질문은 RAG로 단순히 데이터베이스에서 검색하고 조회 가능함.

- 하지만 "오늘 주식 상황을 고려한 현재 연간 매출 또는 ROAS(광고비 대비 매출액)는 얼마야?"와 같은 질문은 단순히 검색만으로는 해결 불가함.

- 이러한 추상적인 요청은 AI 에이전트가 능동적으로 계산하고 구체화해야 하는 부분임.

- 'Agentic'이라는 용어는 AI에게 더 다양한 작업을 요청하고 AI의 활동 범위를 넓히려는 관점에서 나옴.

- <strong>RAG와 Agent AI의 관계:</strong>

- RAG는 기본적으로 검색에 가까움 (네이버/구글 검색처럼 사내 규정을 검색하는 것).

- AI 에이전트는 검색 도구를 사용할지, 어떻게 사용할지 궁극적으로 AI가 결정하게 됨.

- AI가 할 수 있는 일의 범위가 크게 확장되었으며, RAG 검색은 AI 에이전트가 사용할 수 있는 '도구' 중 하나임.

- 이러한 개념들은 매우 빠르게 진화하고 있어 사용자들이 대처하기 어려운 상황임.

## **클라우드 코드 토큰 사용량 1위 경험과 Ultrathink Engineering**

- 한때 클라우드 코드 토큰 사용량 세계 1위를 기록했음 (현재는 3위).

- 사용량 1위에 대해 '5억 원을 지불했느냐'는 오해가 많음.

- 실제로는 무제한 요금제를 사용 중이며, 만약 사용량만큼 지불했다면 약 5억 원에 달했을 것임.

- 이는 약 12억~15억 토큰 사용에 해당함.

- <strong>토큰 사용량의 의미:</strong>

- 토큰은 Input (AI에 전달하는 컨텍스트), Output (AI가 생성하는 최종 결과), Internal token (AI 모델이 내부적으로 사고, 추론하는 과정) 세 가지를 합친 것임.

- 약 15억 토큰이 소모되었다는 것은 AI의 입력, 출력, 내부 사고 과정을 모두 합한 양임.

- 토큰 사용량이 많다는 것은 그만큼 활용성이 높다는 의미이며, 많이 사용해본 사람이 잘 활용하는 노하우를 터득할 수 있음.

- 이 경험을 통해 개인과 기업 차원에서 클라우드 코드 및 코딩 에이전트 도구를 활용하여 생산성을 높이고 비용을 절감하는 방안을 모색함.

- 'Ultrathink Engineer의 Claude Code 활용 팁'이라는 주제의 슬라이드를 기반으로 이야기를 나눔.

## **AI 모델 활용에 대한 철학과 비용 효율성**

- AI 모델의 구독료는 계속 상승하는 추세임.

- 작년 월 20~30달러에서 2025년 10월에는 월 200~300달러가 될 것이라는 전망이 있음.

- 샘 알트만은 프로 플랜 구독자만 추가 플랜을 구매할 수 있는 정책을 언급했음.

- AI 모델이 제공하는 생산성과 현재 구독 플랜 간의 불균형이 존재한다고 생각함.

- 매우 주니어한 프런트엔드 개발자의 월급(최소 210만 원)을 AI 모델 하나가 충분히 커버할 수 있음.

- OpenAI 관련 기사에서는 박사급 연구자들이 개발한 모델에 3만 달러를 청구하겠다는 언급도 있었음.

- AI 모델의 가격에 대한 이중적인 관점이 있음.

- 한편으로는 "지금이 AI 모델을 가장 저렴하게 쓸 수 있는 시기"라는 인식이 있음.

- 다른 한편으로는 '5억 원 상당'의 토큰을 사용한 경험처럼, 비용이 굉장히 비싸지고 있다는 인식이 있음.

- 따라서 '비싸다'와 '저렴하다'를 구분하여 AI 모델 활용을 고려해야 함.

## **무베라-py 개발 사례 및 AI 협업 방식**

- AI와 협업하여 '무베라-py(Muvera-py)'라는 프로젝트를 개발함.

- 무베라-py는 Google DeepMind가 발표한 검색 논문을 기반으로 함.

- 기존 검색 방식보다 약 50배 뛰어난 성능을 보이지만, 초기에는 50배 비싼 비용이 드는 방식이었음 (현재는 1.5배 비쌈으로 개선).

- 원래 C++로 구현된 이 어려운 알고리즘을 파이썬으로 재구현하는 작업을 함.

- 클로드 오푸스 4, 제미니 딥싱크 모델을 활용하여 구현했으며, 당시 GPT5 Pro는 거의 없었음.

- <strong>개발 과정에서의 인간-AI 협업 방식:</strong>

- <strong>1단계: 논문 이해 (인간 주도)</strong>

- 최고의 모델(GPT5 Pro, 제미니 딥싱크 등)과 함께 논문을 읽고 이해하는 데 시간을 보냄.

- 인간이 충분히 이해해야 AI 모델이 잘 구현하는지 피드백을 줄 수 있음.

- <strong>2단계: 기술 사양서(Tech Spec) 작성 (최고 모델 주도)</strong>

- 구현 방안을 논의하고, 'tech spec'이라는 마크다운 파일로 작성함.

- PM(Product Manager)처럼 논문 구현을 위한 요구사항(예: 5가지)을 최고의 모델이 선정하도록 함.

- <strong>3단계: 코딩 CLI(Claude Code, Codex)를 활용한 구현 계획 수립 및 최고 AI의 승인</strong>

- 코딩 CLI가 코드 베이스를 직접 보고 구체적인 계획을 수립함.

- 최고 AI(GPT5 Pro, 제미니 딥싱크 등)로부터 이 계획이 올바른지 승인을 받는 과정을 반복함.

- <strong>무베라-py의 성공과 파급 효과:</strong>

- 구글 딥마인드 논문 기반이었기에 레딧 등에서 큰 인기를 얻음.

- C++ 구현은 즉시 적용하기 어려웠으나, 파이썬 구현은 바로 사용할 수 있어 활용도가 높았음.

- Perplexity 검색 리더 등으로부터 협업 제안을 받고, xAI의 그록 개발팀, 마이크로소프트 AI GBB 등과도 소통하는 계기가 됨.

- <strong>인간 개발자의 역할에 대한 성찰:</strong>

- 이러한 성과로 '천재 엔지니어'가 된 것 같은 착각에 빠질 수 있으나, '나의 에고를 버려야 한다'고 언급함.

- AI(Fun Age 2.5 Pro) 없이는 이런 결과물을 만들어낼 수 없었음을 인지함.

- AI가 주도하고, 인간은 AI가 놓치는 부분을 지적하며 학습하고, 결과물을 함께 만들어가는 관계임을 강조함.

## **코딩 CLI 에이전트 활용에 대한 오해와 전략적 접근**

- 많은 사람이 코딩 CLI 도구(클로드 코드 등)에 대해 큰 관심을 가지고 있음.

- <strong>일반적인 오해:</strong>

- '이렇게 만들어줘'와 같은 추상적인 요청만 해도 코딩 CLI 에이전트가 알아서 작동할 것이라는 생각.

- 이것은 현실과 전혀 다름.

- <strong>오해에 대한 비유:</strong>

- 대학 졸업한 주니어 개발자에게 '카카오톡 만들어봐'라고 하면 바로 만들 수 없고 도망갈 것임.

- AI는 도망가지 않지만, '됐다'고 할 뿐 실제로는 작동하지 않을 것임.

- <strong>현실적인 문제점:</strong>

- 코딩 CLI 도구를 사용해봤지만 잘 작동하지 않는다는 의견이 많음.

- 기존에 잘 작동하던 코드가 있는데 코딩 CLI 도구에 맡겼더니 잘 안 됐다는 사례도 있음.

- <strong>원인:</strong>

- 주니어 엔지니어에게 바로 카카오톡 소스 코드를 읽고 구현하라고 하는 것만큼 어려운 일이기 때문.

- <strong>올바른 활용 방안:</strong>

- 코딩 CLI는 궁극적으로 AI 에이전트이므로, 사람과 일하는 것처럼 대화하고 함께 작업해야 함.

- IT 작업 방식의 변화: 과거 워터폴 방식(요구사항 명확화 후 구현)에서 애자일 방식(요구사항 빠르게 실패하고 지속적으로 피드백 제공)으로 접근해야 함.

- 피드백 제공자는 다른 AI 에이전트, 인간, 도메인 전문가 등 다양하게 존재할 수 있음.

- 코딩 시장의 도구에만 의존하지 않고 전략적으로 접근해야 함.

## **효율적인 AI 에이전트 활용을 위한 '기술 사양서' 작성**

- <strong>문서화의 중요성:</strong>

- 구식처럼 들릴 수 있지만, 문서화(documentation)는 매우 중요함.

- 문서를 잘 작성하면 어떤 AI 모델이 오더라도 구현을 매우 잘 할 수 있음.

- 기술 사양서는 크게 '기술 사양서(Technical Specifications)'와 '계획(Plan)' 두 부분으로 구성됨.

- <strong>기술 사양서의 역할:</strong>

- 무엇을 구현할지, 무엇을 구현하지 않을지, 구현을 통해 달성할 목표가 무엇인지 명확히 해야 함.

- 이는 '자신이 무엇을 원하는지 스스로 아는 것'과도 같음.

- <strong>카카오톡 개발의 구체적 예시:</strong>

- 단순히 '카카오톡 만들어줘'가 아닌, 매우 구체적인 사양서가 필요함.

- <strong>목표 정의:</strong> 메신저, 그룹 채팅, 오픈 채팅방 등 중 어떤 것을 먼저 할 것인지.

- <strong>초기 구현 대상 구체화:</strong> 가장 기본적인 메신저 기능 (송신자-수신자, 메시지 전송).

- <strong>구체적인 요구사항 설정 (예시):</strong>

- 1. 송신자 등록 가능.

- 2. 수신자가 송신자를 친구로 추가 가능.

- 3. 송신자가 수신자에게 메시지 전송 가능.

- 4. 수신자가 송신자의 메시지 읽기 가능.

- <strong>구현하지 않을 것 명시:</strong>

- 오픈 채팅방은 규모가 커서 이번에는 제외.

- 그룹 채팅은 나중에 구현.

- 읽음 확인 기능도 나중에 구현.

- <strong>문서화의 필요성:</strong>

- AI 모델마다, 심지어 같은 모델이라도 새로운 세션에서는 카카오톡 구현에 대해 다르게 생각할 수 있음.

- AI 모델은 그 순간 받아들인 컨텍스트에 기반해서만 결과물을 만들기 때문임.

- 새로운 AI가 작업을 이어받아도 계속 진행할 수 있도록 핸드오버 문서처럼 꾸준히 문서화해야 함.

- 최근 'SDD(Specification-Driven Development)' 접근 방식이나 'Speckit GitHub' 방식처럼 작업 지침을 미리 만들고 진행하는 방식이 개발자와 비개발자 모두에게 중요해지고 있음.

- 명확한 정의, 버전 관리, 문서와 코드의 동기화가 매우 중요하며, 말은 쉽지만 실제로는 어려움.

- 빠르게 시도하고 빠르게 실패하는 것이 중요하며, 기술 사양서는 상황에 따라 변하고 수정되어야 함.

- <strong>기술 사양서의 구체성:</strong>

- 구체적일수록 좋으며, 코드 레벨까지 상세하게 작성해야 함.

- 이 과정에서 가장 비싼 최고의 모델(GPT5 Pro, 제미니 딥싱크 등)과 충분히 논의해야 하며, 이때 토큰 비용을 아끼지 않아야 함.

- 하나의 모델만이 아닌, 같은 수준의 여러 모델(GPT, 제미니 등)과 교차 논의해야 함.

- <strong>다중 모델 활용의 이유:</strong>

- 각 AI 모델(제미니, GPT, 클로드 등)은 본질적으로 다름 (예: 제미니는 수용적, GPT는 발화적).

- AI 모델 훈련 방식, 정제 경향, 데이터셋 분포가 모두 다르기 때문임.

- 예: 클로드는 최신 파이썬에 능숙하나, GPT는 3~5년 전 파이썬 코딩 패턴을 많이 보임.

- 모델별 지식과 행동을 서로 참조하여, 모든 모델의 승인을 받은 후에 진행해야 함.

## **다중 LLM 모델 활용 및 검증 프로세스**

- LLM 모델들과 기술 사양서 논의 시, 본인은 ChatGPT.com을 많이 활용함.

- 본인이 직접 문서를 읽고 개입하여 의견을 줄 수 있어야 하기 때문임.

- 회사 내 태스크포스 초기 회의와 비슷하게, 실무진뿐만 아니라 시니어급 인력도 참여하여 많은 논의를 거치는 것과 유사함.

- <strong>Hugging Face의 Text Embedding Inferencer에 Jina Reranker V3 모델 추가하는 예시:</strong>

- Rust 지식, 머신러닝 지식, 레거시 코드 이해가 필요한 매우 어려운 작업임.

- <strong>1단계: 모델 논문 이해 및 GPT 활용</strong>

- 새로운 모델의 논문을 GPT5 Pro에 넣어 설명을 듣고 충분히 학습함.

- 대화창이 길어질 정도로 꾸준히 질문하며 이해도를 높임.

- <strong>2단계: GPT를 활용한 기술 사양서 초안 작성</strong>

- Hugging Face 저장소에 모델 코드를 넣는다는 가정하에, 목표(goals), 비목표(non-goals), 요구사항(requirements) 등을 포함한 기술 사양서 초안을 GPT에게 요청함.

- 이를 마크다운 파일 형태로 생성하도록 함.

- <strong>3단계: 제미니 딥싱크를 통한 피드백 및 검증</strong>

- GPT의 결과물을 제미니 딥싱크에 복사하여 피드백을 받음.

- GPT는 기준점(Anchor), 제미니는 주요 작업자(Main Worker)로 활용함.

- 제미니의 깊은 사고방식과 GPT의 사고방식이 충돌할 경우, 두 모델의 의견을 조정해야 함.

- <strong>4단계: 코딩 CLI 에이전트를 통한 기술 사양서 검증</strong>

- 합의된 기술 사양서를 클로드 코드나 코딩 CLI 에이전트에게 전달하여 '이 기술 사양서가 맞다고 생각하느냐?'고 검증 요청함.

- 코딩 CLI 에이전트는 코드 이해도가 가장 높으므로, 파일들을 보며 GPT와 제미니 간의 사양서 격차를 확인시킴.

- <strong>5단계: 다중 모델을 활용한 의견 수렴 및 표준화</strong>

- 코딩 CLI 에이전트의 개별 결과들을 다시 GPT5 Pro와 제미니 딥싱크에 넣어 의견을 취합함.

- GPT5 Pro의 결과물(영혼의 산출물)을 표준으로 삼고, 제미니 딥싱크는 보충/피드백 검토 역할을 함.

- 이 과정을 통해 역할극(role-play)을 하여 모든 의견을 모아감.

- <strong>6단계: '기술 사양서 협의회' 반복 (합의 도달까지)</strong>

- GPT, 제미니 딥싱크, 클로드, 코덱스 등 5~6개 모델들이 모두 'OK' 사인을 줄 때까지 의견 조율을 반복함.

- 중간에 특정 모델이 이상한 의견을 내면 인간이 직접 개입하여 차단하거나 피드백을 제공함.

- 이러한 조정 과정에는 MCP(Multi-agent Communication Protocol) 친구를 활용할 수도 있음 (예: 젠 MCP의 JeCP 방식).

## **LLM 모델과의 협업 시 대기 시간 활용법**

- LLM 모델이 작업을 수행하는 동안 발생하는 대기 시간은 두 가지 방식으로 활용함.

- <strong>1. 이해도 향상:</strong>

- 초보자의 경우 문서만 봐도 시간이 부족하므로, 모델의 작업을 기다리면서 문서 등을 직접 보며 학습함.

- <strong>2. 피드백 준비:</strong>

- 매우 난이도가 높거나 기술적인 난이도가 높은 작업의 경우, 모델이 올바른 방향으로 진행하는지 이해하고 피드백을 줄 수 있도록 해당 내용에 집중하여 학습함.

- <strong>3. 다른 작업 병행:</strong>

- 난이도가 높지 않은 단순한 기능 추가 작업의 경우, 여러 작업을 동시에 위임하고 그 시간 동안 다른 업무를 처리함.

- 난이도가 낮으면 3~4개 이상의 작업을 동시에 진행할 수도 있음.

- 난이도가 높으면 하나의 작업에 집중하는 편임.

- <strong>일반적인 오해 불식:</strong>

- AI에게 맡겨두면 알아서 될 것이라는 오해를 많이 함.

- 실제로는 AI의 능력을 극대화하기 위해 인간의 노력이 필요함.

- 많은 토큰을 사용한다는 것이 무작정 질문을 던지고 대충 활용하는 것이 아님.

- 오히려 AI의 답변을 정제하고, 인간이 관리자처럼 개입하여 조정하는 과정을 거침.

## **'계획(PLAN.md)' 수립 및 이터레이션 과정**

- 기술 사양서만으로는 부족하며, 기술 사양서가 '무엇을 할지' 설명하는 문서라면, '오늘 무엇을 할지'에 대한 구체적인 계획이 필요함.

- AI 모델을 '아무것도 모르는 주니어 개발자'로 여기고 친절하게 설명해야 함.

- 기술 사양서만 바로 주면 AI가 '뭘 해야 할지 모르겠다'고 할 수 있으므로, '앉아서 이것만 해라'는 식으로 구체적인 계획이 필요함.

- <strong>PLAN.md 작성 방법:</strong>

- 기술 사양서를 작성할 때와 동일하게 여러 모델과 논의하여 작성함.

- 기술 사양서가 이미 견고하다면, 이 계획 수립 단계부터 자동화도 가능함.

- 이 단계부터는 코딩 CLI 에이전트와의 논의를 매우 중요하게 여김.

- 코딩 CLI 에이전트는 코드 파악 및 컨텍스트 이해도가 높기 때문에, ChatGPT.com 같은 도구는 더 이상 사용하지 않음.

- 기술 사양서가 청사진이라면, PLAN.md는 실무자들이 모여 세부 사항을 논의하는 회의와 같음.

- <strong>PLAN.md의 구체적 내용 및 활용:</strong>

- PLAN.md는 구현 가이드라인이자 마일스톤(milestones)으로 볼 수 있음.

- 다수의 이모지가 사용된 PLAN.md 예시를 통해, 클로드 코드 소넷 4.5를 메인 모델로, 제미니 CLI 등 다른 에이전트들이 피드백을 제공하는 방식임을 보여줌.

- 클로드 코드 소넷 4.5가 작업을 진행하는 동안 다른 코딩 에이전트들이 MCP(Multi-agent Communication Protocol)를 활용하여 지속적으로 피드백을 제공함.

- 마일스톤(예: 9개의 마일스톤)이 올바르게 선정되었는지, 순서는 맞는지, 올바른 지점에서 끊어졌는지 등을 검토하고 피드백하며 합의될 때까지 반복함.

- 기술 사양서 작성에 2일, 계획 수립에 3시간 정도 소요되었으며, 총 4일 정도의 작업임.

- 마일스톤 하나가 클 경우, 세션 켜고 클라우드 코드를 가동하여 구현하며, 이 안에 서브태스크(sub-tasks)를 두어 하나씩 해제할 수 있음.

- 클로드 4.5 모델은 컨텍스트를 언제 끊어야 할지 알고 있어 마일스톤 설정에 도움을 줌.

- <strong>실행 및 업데이트:</strong>

- PLAN.md가 완성되면, '감지 로직(detection logic)'과 같은 특정 작업만 수행하고 세션을 종료한 후 코드를 커밋/업로드함.

- 'All done' 메시지가 나오면 사람이 확인하고 피드백을 주거나, 자동화된 테스트를 통해 검증함.

- PLAN.md를 지속적으로 업데이트해야 함. 마일스톤 완료 시 'V' 표시를 하고, 다음 완료되지 않은 작업을 수행하도록 함.

- 다음 작업자를 위해 PLAN.md에 필요한 수정 사항이나 참고 사항을 노트로 작성함.

- <strong>버전 관리와 커밋:</strong>

- PLAN.md는 직접 업데이트하거나, AI가 작업 완료 후 개선 계획을 스스로 작성하게 할 수 있음.

- 버전 관리가 중요하므로, 하나의 커밋에 하나의 마일스톤 또는 서브태스크만 포함시켜야 함.

- 이는 소프트웨어 공학의 '하나의 커밋은 하나의 작업/기능만 생성한다'는 원칙과 일치하며, 머신러닝 커밋 기능과 잘 통합하여 활용해야 함.

## **Claude.md (시스템 프롬프트)의 중요성 및 상세 작업 지침**

- Claude.md는 현재 코딩 시에라 에이전트가 어떻게 작동해야 하는지에 대한 매우 강력한 지시를 담은 시스템 프롬프트임.

- <strong>Claude.md의 주요 지침 예시:</strong>

- 어떤 작업이든 시작하기 전에 반드시 기술 사양서(tech spec)를 매우 주의 깊게 읽을 것 (이 과정에서만 3만 토큰 이상 소모될 수 있음).

- 기술 사양서에 기반하여 이 '계획(plan)'을 구현하는 데 모든 에너지를 집중할 것.

- 모르는 것이 있다면 기술 사양서에 질문할 것.

- 기술 사양서와 계획만 있다면 어떤 모델이든 구현 가능함 (단, 모델이 너무 약하면 작동하지 않음).

- 'go' 명령을 받으면 plan.md를 보고 아직 구현되지 않은 마지막 항목을 구현할 것.

- <strong>테스트 주도 개발(Test-Driven Development) 방식:</strong>

- 가장 먼저 테스트(test)를 작성할 것.

- 테스트가 있어야 정량적으로 실패/통과 여부를 평가할 수 있음.

- 이 테스트를 구현하기 위한 최소한의 코드만 작성할 것.

- AI 모델에게 맡기면 코드를 갑자기 확장하거나 많은 변경을 가하여 인간이 피드백하기 어려워지기 때문임.

- 매우 작은 변화만 남기도록 해야 함.

- <strong>규칙 기반 강제 및 세션 종료 전략:</strong>

- 만약 최소한의 코드 작성 지침이 충분하지 않으면, 100줄을 초과하면 세션을 종료하는 등 규칙 기반으로 강제할 수 있는 프롬프트를 만들 수 있음.

- <strong>세부 구현 단계에서의 반복 작업:</strong>

- 테스트 실행 -> 컴파일러 피드백 -> 테스트 실행 -> 구현 과정을 반복함.

- 이 1, 2, 3단계가 모두 만족될 때까지 반복적으로 수행함.

- 예시로 든 '감지 로직(detection logs)과 프로젝터 검증' 작업에 대해서만 이 과정을 반복함.

- MCP 등을 활용하여 다른 코드 에이전트로부터 지속적으로 피드백을 받으면서 계획을 반복적으로 구현해나감.

- <strong>AI의 '플랜 모드'와 인간의 'PLAN.md' 구분:</strong>

- Techspec.md는 경영진의 지시와 같음.

- PLAN.md는 상사가 오늘 '나에게' 지시한 할 일과 같음.

- 클로드 코드 자체의 '플랜 모드'는 AI가 스스로 '이걸 먼저 읽을까? 아니면 이걸 먼저 실행해볼까?' 하고 고민하는 AI의 내면의 생각과 같음.

- 계획을 꾸준히 업데이트하며, 작업이 완료될 때마다 'V' 표시를 하고 새로운 세션을 열어 다음 작업을 진행하도록 함.

- 다음 작업자를 위해 'plan.md'에 수정 사항이나 필요한 정보를 남기도록 지시함.

## **향후 논의 예정 사항**

- 오늘 준비된 내용 중 약 20% 정도만 진행됨.

- 나머지 클라우드 코드 및 코딩 에이전트의 활용 노하우, 토큰 사용 경험 등은 다음 시간에 더 깊이 있고 쉽게 설명할 예정임.

- 시간 제약으로 인해 두 부분으로 나누어 다음 회차에 나머지 내용을 다룰 것을 제안함.

#AI에이전트 #클라우드코드 #토큰사용량 #개발노하우 #기술사양서 #PLAN.md #SDD #LLM활용 #인간AI협업 #애자일개발 #PsionicAI #무베라py