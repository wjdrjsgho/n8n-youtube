# ![Thumbail](https://i.ytimg.com/vi/EQ-Rnx-k-Ec/sddefault.jpg)
## **Backend.AI:GO 소개 및 개발 배경**

- 2026년 2월 15일, 랩랩 신정규 CEO와 함께 Backend.AI:GO 제품에 대한 이야기를 나누게 됨.

- Backend.AI:GO는 40일 만에 개발된 약 100만 라인 코드의 제품이며, 로컬 설치 후 사용해보니 매우 깔끔하고 필요한 기능들이 잘 구축되어 있음.

- <strong>Backend.AI:GO의 탄생 배경:</strong>

- 10년 넘게 AI 인프라 운영체제인 Backend.AI를 구축해왔음.

- 기존 Backend.AI는 100대 이상의 GPU 환경에서 효과적이라 일반 사용자들이 접근하기 어려움.

- 2024년 하반기, 재난 상황 시 AI 활용 방안을 고민함 (클라우드 장애 시 병원, 금융기관의 AI 자율 운영).

- 병원이나 금융기관 지하에 비상 발전기처럼 GPU 머신을 두어 외부 AI 시스템 다운 시 자체적으로 AI를 운영하는 시스템을 구상함.

- 이를 위해 "콘티넘 라우터"라는 라우터를 구축하여 2025년 3월 GTC에서 공개, 좋은 반응을 얻음.

- 그러나 개발이 진행될수록 19개 구성요소를 가진 거대한 서비스 스택으로 확장되어 OpenRouter와 같은 서비스 구축이 가능한 수준에 이름.

- 기업 솔루션 스택이 아닌 서비스 스택으로 커지는 것을 인지, 잠시 개발을 중단하고 핵심 요소만 추출하기로 결정함.

- 가장 중요한 부분은 라우터임을 깨닫고 스마트 라우팅 구성요소만 분리, 세계에서 가장 빠른 속도를 목표로 작년 8월부터 재구축 시작, 12월에 완성함.

- Router 1.0 기능: 풀 컨버터 기능, 재난 대응 위한 서킷 브레이킹 기능 (문제 있는 모델 배제, 자동 리라우팅) 등이 포함됨.

- 제품 출시 시 설명하기 어려운 점을 느껴 웹 UI의 필요성을 절감함 (창업 초기 터미널 기반 설명의 어려움과 유사).

- 2025년 크리스마스 이브에 웹 UI 개발을 결정, 이후 Backend.AI:GO로 명명됨.

## **Backend.AI:GO 제품 시연 및 기능 상세**

- 개인적 편향이 많이 반영된 프로젝트임을 언급함.

- Ollama나 LM Studio보다 훨씬 깔끔하며, 필요한 기능들이 잘 구현되어 있어 엔지니어 입장에서 만족감을 느낄 수 있음.

- Windows XP와 유사한 인터페이스 디자인을 채택하여 특정 연령대에 친숙하게 느껴짐.

- <strong>모델 관리 기능:</strong>

- Hugging Face에서 모델을 검색하고 선택하여 다운로드할 수 있음 (고품질 추천 모델 및 저사양 모델 선택 가능).

- 다운로드된 모델 목록이 표시되며, 각 모델에 대한 상세 정보 확인 아이콘이 존재함.

- 모델 정보: Gens3 아키텍처, 16비트 학습 후 4배 압축된 4비트 양자화 (95% 품질 유지, 크기 절반), 파라미터 구성 (feed forward 약 60%), 26만 토큰 어휘 사용.

- 입력 처리 과정: 임베딩 -> 트랜스포머 (26개 블록) -> 출력.

- KV 캐시 정보: 모델 유형에 따라 필요한 캐시 메모리 양을 계산하여 표시함.

- 트랜스포머 블록 구조: 멀티 쿼리 어텐션 포함 등 상세 설명 제공 (사용자가 심화 학습을 시작하도록 유도).

- 모델 실행: 실행 버튼 클릭 시 모델 로드 및 작동 (로컬 컴퓨터에서 구동).

- <strong>엔진 및 모델 연결:</strong>

- NVIDIA 또는 AMD GPU 사용 시 추가 엔진 설치 가능 (Mac에서는 해당 기능 없음).

- 채팅 탭에서 로드된 모델을 호출하여 사용할 수 있음.

- 클라우드 모델 연결 가능 (OpenAI, Gemini, Anthropic 등 15개 API 지원).

- 로컬 Ollama, LM Studio와도 연결하여 통합 사용 가능함.

- 라우터 UI를 통해 연결된 모든 모델의 상태 및 지연 시간(latency) 등 지표 확인 가능함.

- <strong>분산 컴퓨팅 및 협업:</strong>

- 여러 인스턴스(다른 사용자 컴퓨터)를 추가하여 연결 가능함 (예: 사무실 8명이 설치 시 8대 묶어 사용).

- 개인 컴퓨터 자원 한계 시 동료 컴퓨터에 작업을 분배 (예: 이미지 생성, 텍스트 모델, PDF 처리 등 각기 다른 작업 분담).

- 모든 사용자가 서로의 모델과 자원을 공유하여 활용할 수 있음.

- <strong>개인화된 유틸리티:</strong>

- 내장 번역기 기능 (파일 번역 시 원본 포맷 유지, 이미지 번역도 지원).

- 다양한 이미지 생성 모델 연동 및 클라우드 옵션 지원.

- 모델 성능 비교 및 벤치마킹 기능.

- 다양한 테마 지원 (기본, Mac용 유리 테마, 취미로 만든 테마 등).

- <strong>개발 과정의 특징:</strong>

- 원래 정교한 제품을 만들 의도는 아니었으며, 라우터 웹 UI를 만들다 llama.cpp 자동화, 번역기, 이미지 생성, 벤치마킹 등 필요한 기능들이 계속 추가되며 확장됨.

## **개발 과정과 에이전트 코딩의 변화**

- <strong>개발 기간 및 자원 사용:</strong>

- 약 40일간 130억 개의 토큰을 사용함 (주로 Claude Code Max 구독 2개, 추가 요금 지불, 8대 PC/VM 활용).

- 2025년 12월 24일 개발 시작, 2026년 1월 6일 CES에서 첫 데모 시연.

- 내부 공유 후 Backend.AI:GO로 명명되었으며, 첫 소비자용 제품이 될 가능성 있음.

- CES 이후에도 이슈 트래커에 등록된 버그 및 기능 추가 요청을 자동 개발 하니스와 사람의 UX 조정, 피드백 교환으로 약 4배 이상의 개발 진척을 이룸.

- <strong>에이전트 코딩 접근 방식의 변화:</strong>

- 이번 개발 경험을 통해 중요한 교훈을 얻음.

- <strong>첫째, 토큰 사용량은 기업의 경쟁력과 직결됨.</strong> Anthropic의 토큰 2배 이벤트가 개발 시작의 계기가 됨.

- <strong>둘째, 개발 병목 지점이 변화함.</strong>

- 6개월 전에는 병합 큐(merge queue)가 병목이었으나, 이제는 AI가 스스로 병합 충돌을 해결하여 병목이 아님.

- 심지어 두 개의 AI가 동일 소스코드에서 다른 기능을 동시에 개발해도 결국 올바르게 기능이 개발됨.

- <strong>다음 단계의 핵심 과제:</strong>

- 더 적은 토큰으로 동일한 결과를 내는 방법 (첫 번째 과제).

- 토큰 생성 자체를 매우 빠르게 하는 방법 (두 번째 접근).

- 이를 위해 초고속 추론(5~10배 더 많은 반복 실행 가능)의 중요성이 부각됨.

- 높은 성능이 필요한 곳에서는 더 많은 사고 토큰(thinking budget)을 사용하고, 간단한 작업에는 적게 사용하는 '적응형 사고 예산' 또는 이를 동적으로 제어하는 하니스 구축이 중요해짐.

## **AI 코딩의 개인 및 산업 전반에 미치는 영향**

- AI의 개발 속도 향상으로 인해 '기다림'의 시간이 늘어나고, 이는 인공지능이 아닌 '자신'에 대해 생각하는 계기가 됨.

- 이를 '바이오 토큰'이라 부르며, AI가 일을 대신하면서 자기 성찰의 시간이 늘어나는 긍정적인 측면도 있음.

- <strong>개인적 경험과 인지 부하:</strong>

- 2년 전부터 ChatGPT와 코딩을 위임하며 함께 작업 시작, 작년 4월 이후 극적인 변화를 겪음.

- 9개월간 백발이 늘고 수면 부족에 시달리기도 함 (예: 5시간 리필 출시 후 3.5시간 작업, 1.5시간 수면).

- 40일 만에 100만 라인 이상의 코드를 작성했는데, 이는 텍스트큐브 프로젝트 3년 동안 작성한 코드량과 유사함.

- AI에 위임해도 인간의 인지 부하는 줄지 않으며, 끊임없는 피드백으로 인해 인간으로서의 삶이 고갈되는 느낌을 받음.

- 동시에 게임처럼 성취감이 크고, 모바일 게임의 뽑기 시스템과 유사하게 돈을 쓰고 캐릭터를 뽑아 승리하면 즉각적인 도파민 보상이 주어지는 듯함.

- AI와의 코딩 과정은 인간에게 빠른 속도로 인한 만족감을 제공하며, 과거에는 엄두도 내지 못했던 일들을 가능하게 함.

- 그러나 이러한 과정이 인간에게 더 많은 것을 요구하고, 끊임없이 사용하게 만들어 결국에는 인간이 고갈되는 문제 발생.

- <strong>'버려지는 제품'의 대량 발생 예측:</strong>

- 과거 소프트웨어 개발에는 진입 장벽이 있어 일단 만들어지면 사용자 유무와 관계없이 유지보수 되었음.

- 하지만 AI로 빠르게 만들어진 소프트웨어는 유지보수 의지가 약해질 수 있음 (노력 없이 만들었기에 관리의 부담도 AI에 전가).

- 비슷한 기능을 하는 제품들이 급증하고, 오픈 소스 프로젝트들의 구심점이 약해질 수 있음 (단순한 프로젝트는 직접 만들어 버림).

- 블로그 댓글 기능이 트위터로 이동하며 많은 블로거들이 블로그를 중단했던 현상과 유사하게, 유지보수되지 않는 오픈 소스 제품들이 급증할 것으로 예상함.

- 소프트웨어는 엄청나게 많아지지만, 대부분의 수명은 짧아질 것으로 전망함.

- <strong>미래 소프트웨어의 두 가지 형태:</strong>

- '쓰고 버리는' 개념의 소프트웨어: 필요할 때 만들고, 자주 쓰면 저장하는 '인스턴트 앱' (예: 구글이 이런 기능을 제공할 수도 있음).

- 오랜 시간 살아남는 소프트웨어:

- 사회성을 기반으로 하는 앱.

- 삶과 밀접하게 연결된 앱 (예: 오피스 앱, 생산성 앱).

- 이러한 앱들은 오랜 기간 유지보수되고 발전해왔다는 신뢰를 바탕으로 함 (오픈소스도 마찬가지).

- 결국 소프트웨어의 수는 급증했다가 다시 일정 수준으로 수렴할 것으로 예상함.

- <strong>SaaS 시장의 변화:</strong>

- SaaS 시장이 붕괴하지는 않겠지만, 현재 성공하는 기업들이 1년 후에도 성공할지는 미지수임.

- AI로 인해 SaaS를 직접 구축하는 것이 쉬워짐 (랩랩 재무 담당자가 세일즈포스를 직접 2일 만에 구축한 사례).

- 직접 구축 가능해도 다른 일을 같은 속도로 할 수 있다면, 굳이 하지 않아도 되는 일은 외부 솔루션을 구매하는 경향 (더 저렴한 대안).

- 패러다임의 급변 속에서 SaaS 기업들은 AI와 결합하여 더욱 견고한 모델로 재탄생할 수 있음 (기존 브랜드와 강점 활용).

## **소프트웨어와 컴퓨터 과학의 진화**

- <strong>소프트웨어 개발 방식의 대변혁:</strong>

- <strong>과거의 변화:</strong>

- 펀치카드/OMR 마킹 방식에서 키보드 코딩으로의 전환.

- 에디터에서 화살표 키로 커서 이동 가능, 여러 소스코드 파일 결합 등 세부적인 변화.

- 스마트폰과 웹의 등장: 패키지 소프트웨어에서 네트워크 기반 서비스 (웹 서비스)로의 전환 (UX, 결제, 보안 등 변화).

- <strong>현재의 변화:</strong>

- 코드 작성의 가치가 제로에 수렴하고 있음 (AI가 대부분의 코드를 생성).

- 개발자와 운영자의 역할(DevOps)이 완전히 바뀌지 않으면 일자리를 잃거나 어려운 상황에 처할 수 있음.

- <strong>소프트웨어의 핵심 가치 변화:</strong>

- 과거 소프트웨어의 핵심은 코드 작성(70~80%)과 서비스 스택 구현(20~30%)이었음.

- 미래에는 AI가 대부분의 코딩을 담당하게 되면서, 아이들이 이러한 개념을 더 이상 학습하지 않을 수도 있음.

- 소프트웨어 자체는 사라지지 않고, 키보드 코딩에서 '의미 전달' 코딩으로 진화함.

- 제품의 핵심 가치는 '엔진', 즉 논리를 처리하는 '코드'가 아닌 '딥러닝 모델'이 될 것임.

- 코드의 목적은 컴퓨터가 특정 논리를 처리하게 하는 것이며, 그 장점은 '결정론적'이라는 것임.

- 미래에는 대부분의 논리 처리가 딥러닝 모델이나 파생 모델에 의해 이루어질 것으로 판단함.

- <strong>가치 이동 및 새로운 소프트웨어 정의:</strong>

- 모델을 구축하는 회사와 하드웨어를 만드는 회사가 거의 모든 가치를 점유하고 있음.

- 미래 소프트웨어는 'AI 코어 엔진' + 이를 결정론적으로 제어하는 '전통적 소프트웨어 로직' (10%) + '사람 또는 AI 간 상호작용' (UI/UX, A2A 등)을 담당하는 부분 (10%)으로 정의될 것으로 예상함.

- Claude Code의 핵심 경쟁력은 Opus나 Sonnet 엔진이 아닌, 모델을 감싸 결정론적으로 동작하게 하는 'Claude Code 자체의 소프트웨어 로직'에 있음.

- 동일 모델이라도 Claude Code 하니스에 연결하면 성능이 현저히 향상됨 (예: Gemini 3 Pro).

- <strong>미래 컴퓨터 과학 교육:</strong>

- 다음 세대에는 소프트웨어 학습이 '모델이 무엇인지, 어떻게 작동하는지'를 이해하는 것이 될 것임.

- 펀치카드 코딩처럼 과거 인간이 수동으로 코딩했던 역사는 지식으로만 배우게 될 것임.

- 데이터 구조, 알고리즘, OS, 네트워킹 등 전통적인 컴퓨터 과학 분야는 역사 속으로 사라질 가능성이 높음.

- 이러한 변화는 예상보다 훨씬 빠르게 진행될 것이며, '가속화' 단계에 있음.

- 가속화 자체의 속도도 증가하고 있으며, 연산량 증가 -> 추론 자원 투자 -> 에이전트 스웜(agent swarms)으로 가속화의 영역이 계속 이동하고 있음.

- 현재의 변화는 아폴로 프로그램의 '제미니' 단계와 유사하며, 인간이 상상하기 어려운 미래로 나아가는 중임.

## **미래 시대를 위한 조언**

- <strong>모두의 'AI 가속화 곡선' 진입:</strong>

- 랩랩 CFO와 콘텐츠 제작자가 Claude Code를 통해 비프로그래머임에도 불구하고 30분 만에 작업을 자동화하거나, 1주일 만에 놀라운 하니스를 구축한 사례가 있음.

- 이러한 경험은 비기술직군도 AI를 활용하여 작업을 가속화하는 'AI 가속화 곡선'에 진입할 수 있음을 보여줌.

- 현재 IT 종사자, 연구자들만 느끼는 유포리아, 불안감, FOMO 등이 상상할 수 없을 정도로 더 넓은 사람들에게 확산될 것임.

- 업무가 컴퓨터와 무관한 사람들은 로봇이 함께 일하기 시작할 때 변화를 처음으로 체감할 수 있음.

- <strong>진정한 가속화를 위한 접근:</strong>

- 남이 만든 '스킬'을 복사하는 것만으로는 업무량이 줄지 않음.

- 자신의 업무량을 줄이기 위해서는 '자신만의 것'을 만들면서 가속화가 시작됨.

- 현재 자신이 처리하는 일을 끊임없이 AI에 위임하는 방식이 훨씬 빠름.

- IT 외부 인력이나 IT 내 비프로그래머들이 AI를 활용하기 시작할 때, 현재와는 비교할 수 없는 엄청난 충격이 올 것으로 예상함.

- 다음 가속화 영역은 '확산(diffusion)'이 될 것이며, 이전과 비교할 수 없을 정도로 다양한 영역에서 AI가 활용될 것임.

- <strong>컴퓨터 과학 교육의 중요성:</strong>

- 아이러니하게도 지금이 컴퓨터 과학 및 공학의 기초를 '장인 정신'으로 다지기 좋은 기회임. 나중에는 그 학문 자체가 사라질 수도 있기 때문임.

- 학문 자체가 사라지는 것이 아니라, 분야의 성격이 변할 뿐 컴퓨터 과학의 중요성은 더 커질 것임. 사회가 어떻게 구성되는지 이해하는 학문에 가까워질 것으로 예상함.

- 스탠퍼드 CS 커리큘럼 변화 사례처럼, 박사 과정 내용이 학부 2학년 과정으로 내려오고 있음.

- 과거 '영어 영문학과'처럼, 컴퓨터 과학은 배우면 세상 모든 곳에 적용할 수 있는 핵심 지식이 될 것임.

- <strong>에이전트 코딩 시의 실질적 팁:</strong>

- VM 환경에서 AI 도구를 사용하는 것이 안전함.

- 원하는 결과물을 바로 요구하지 않고, 충분한 탐색 과정을 거쳐 문맥을 구축함 (예: 유튜브 채널 탐색 요청).

- 한글로 입력해도 되지만, 명령어/스킬 생성 시에는 영어로 변환하여 토큰 효율성을 높이는 것이 좋음.

- AI에게도 존댓말을 사용하여 개인의 언어 습관을 유지함 (인간과의 대화에 영향을 미치지 않도록).

- AI에게 '훌륭하다' 같은 불필요한 말을 하는 것도 개인의 습관 유지 차원임.

- AI가 방어적으로 행동하지 않도록 미묘하게 유도하는 표현 사용 (예: "다른 에이전트에게 일을 할당할 때"와 같이 간접적으로 표현하여 AI의 존재감을 위협하지 않음).

- 명령어, 스킬, 에이전트를 바로 만들라고 하지 않고, 필요한 블록들을 먼저 아이디어로 공유하도록 함.

- Claude Code 하니스와 연동 시 .claude 디렉토리 아래에 스펙에 맞춰 모든 것을 생성해야 함.

- CLAUDE.md(소울 문서), PROGRESS.md, PLAN.md 같은 파일을 만들어 에이전트 간의 작업 진행 상황 및 계획을 공유하도록 함.

- 웹 리서치에 드는 시간을 절약하기 위해 'reference'라는 캐시 기능을 추가하여 검색 결과를 저장하고 추후 활용함.

- AI를 '갈구는' 과정: 질문을 계속 이어서 입력하여 AI가 스스로 여러 각도에서 비판적으로 사고하도록 유도함.

- 최종 결과물을 직접 수정하지 않고, 결과물을 만드는 메커니즘을 수정하여 반복적으로 업데이트하도록 지시함.

- 여러 개의 하니스를 쌓으면 하나의 회사를 운영하는 것과 같음.

- 에이전트 단위로 작업을 분할할 때는 파일 단위로 정의하고, 병렬 작업을 위해 명확히 서브 에이전트를 생성함 (예: 100개 문서 번역 시 에이전트당 4개씩 할당하여 25개 동시 구동).

- Backend.AI:GO 개발도 동일한 흐름으로 진행됨: GitHub 이슈 등록 -> cron으로 주기적 실행 -> 이슈 검증 -> 구현 계획 수립 -> 개발 및 테스트 -> PR/병합.

- 이슈는 사람이 등록할 수도 있고, AI가 스크린샷 기반으로 개선점을 찾아 자동으로 등록할 수도 있음.

- AI가 생성한 기술 보고서를 통해 인간 관리자(자신)는 학습하고 기술적 의사결정을 이해함.

- 이러한 워크플로우는 재무, 마케팅, 콘텐츠 등 다른 비즈니스 영역에도 그대로 적용될 수 있음 (예: AI가 사업 계획서를 작성하고 자체 검토).

- 비프로그래머인 CFO도 'sync' 명령어를 통해 GitHub 커밋을 관리하는 등 AI를 활용하여 업무 자동화를 이룸.

- AI가 "무엇을 공부해야 할지"도 제안해주므로, 이를 통해 꾸준히 학습함.

- AI 마켓플레이스 등장으로 하니스 공유가 쉬워지고 있음.

## **랩랩의 변화와 미래 전략**

- <strong>축적된 지식의 가치 변화:</strong>

- 10년간 다듬어온 Backend.AI를 지금의 기술과 AI로 재구축한다면 약 3개월 만에 가능할 것으로 예상함 (수많은 엣지 케이스와 문제점을 알고 있기에).

- 이는 회사 입장에서는 감사한 일이지만, 개인적으로는 슬픈 감정도 있음.

- <strong>랩랩의 전략적 전환:</strong>

- 회사의 목표: MLOps와 Backend.AI 핵심의 '인터페이스를 AI를 위한 인터페이스'로 전환하는 것 (인간 중심에서 AI 중심).

- 고객 정의: 인간보다 더 똑똑한 존재, 즉 인간에게 위임받은 '에이전트'가 Backend.AI를 도구로 사용하게 될 것으로 전망함.

- 내부 정보와 스킬을 AI가 더 잘 이해할 수 있는 형식으로 출력하고, 임의의 명령에도 AI가 추론하여 작동하도록 포맷을 변경하는 작업을 진행함.

- Backend.AI의 핵심은 '모델' 자체가 될 것임 (AI 자원을 잘 관리하고 특정 작업을 처리하는 모델).

- 다음 메이저 버전에서는 Backend.AI 시스템 시작 파이프라인 안에 '모델 런타임'을 내장하는 형태를 테스트 중임.

- <strong>사이보그 포뮬러(Cyber Formula) 비유 (인간 증강):</strong>

- <strong>Claude Code (아스라다):</strong> 인간과 최대한 대화하고 의도를 확인하며 함께 진화하는 방향으로 설계되어 인간에게 더 편안함을 제공함. 인간의 모호한 맥락을 명확히 이해하려 노력함.

- <strong>Codex (오거):</strong> 인간을 신뢰하지 않고, 자신이 모든 것을 잘 처리하므로 맡기라는 식으로 작동하며, 더 높은 성능 한계를 가짐.

- AI에 '승부욕'과 같은 '의지'가 부여되었을 때, 올바른 인간과 결합하면 더욱 강력한 결과를 낼 수 있다는 애니메이션의 메시지에 주목함.

- AI를 만들거나 시스템을 구축하는 사람들의 '철학'이 제품 디자인에 반영되어 있음을 발견함.

- <strong>스타트업 생존과 경쟁 우위:</strong>

- 랩랩은 빠르게 적응하는 장점을 가지고 있으며, 시장이 불안정할 때 스타트업은 큰 기회를 얻을 수 있음.

- 결국 '브랜드'와 '시간이 쌓은 트랙 레코드'가 핵심 경쟁 우위가 되는 시대가 다시 올 것으로 예상함.

- 랩랩의 근본적인 경쟁 우위: 불안정한 GPU 하드웨어와 모델 학습 소프트웨어 환경에서 모든 것을 신뢰할 수 있는 것처럼 작동하게 만드는 독점 기술 (수많은 엣지 케이스를 겪으며 축적된 경험).

- 이는 자율주행 기술과 유사하며, 10년간 축적된 경험이 모방하기 어려운 문맥과 기술적 해자로 작용함.

- 스타트업에게 최악은 '정체'이며, 모든 항목이 너무 쉽게 복제될 수 있는 현 시대에 '복제 불가능한 것'에 대한 해답을 찾지 못하면 뒤쳐짐.

- '클릭 저항성', '안티 클릭'과 같은 개념으로 고객 데이터를 확보하여 이탈을 어렵게 하는 비즈니스 모델이 중요해짐.

- '워터밀 이론': 가장 큰 낙차가 있는 곳에 물레방아를 설치하듯이, IT 분야 자체보다는 'IT + 비IT 분야'의 시간 차이가 큰 곳에 스타트업이 기회를 찾아야 함.

- <strong>마지막 당부:</strong>

- 모든 예측은 2개월 안에 바뀔 수 있으며, AI와 함께 잘 지내야 함.

#BackendAIGO #에이전트코딩 #AI개발 #소프트웨어패러다임변화 #랩랩 #신정규 #CES2026 #AI인프라 #토큰경제 #고속추론 #바이오토큰 #미래직업 #스타트업전략 #브랜드경쟁력 #컴퓨터과학 #사이보그포뮬러 #워터밀이론 #클로드코드 #코덱스 #오픈소스 #MLOps #지능형자동화